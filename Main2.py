# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ghkvl-2kEM8CEY0zI-SoXrxUKYNxw9Op
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.tree import DecisionTreeClassifier

#1

file_path = 'water_potability.csv'

dataset = pd.read_csv(file_path)


print(dataset.head())

#2

#menampilkan jumlah baris,kolom,typedata dan nilai unik
print(dataset.info())

#3

# Check for missing values
print(dataset.isnull().sum())

# mengganti missing values dengan mean
dataset = dataset.fillna(dataset.mean())

#check kembali
print(dataset.isnull().sum())

# menentukan batas outlier
for col in dataset.columns:
  q1 = dataset[col].quantile(0.25)
  q3 = dataset[col].quantile(0.75)
  iqr = q3 - q1
  lower_bound = q1 - (1.5 * iqr)
  upper_bound = q3 + (1.5 * iqr)

  # Menghitung nilai rata-rata dari kolom
  mean_value = dataset[col].mean()

  # menggantikan outlier dengan nilai rata-rata
  dataset[col] = dataset[col].apply(lambda x: mean_value if x < lower_bound or x > upper_bound else x)
print(dataset.head())

plt.figure(figsize=(6, 4))
sns.countplot(data=dataset, x='Potability')
plt.title("Distribusi Data Kualitas Air Sebelum Resampling")
plt.xlabel("Potability")
plt.ylabel("Jumlah")
plt.show()


stratified_sample = dataset.groupby('Potability', group_keys=False).apply(lambda x: x.sample(2, random_state=1).reset_index(drop=True))

plt.figure(figsize=(6, 4))
sns.countplot(data=stratified_sample, x='Potability')
plt.title("Distribusi Data Setelah Resampling")
plt.xlabel("Potability")
plt.ylabel("Jumlah")
plt.show()

#4

fitur = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity','Organic_carbon', 'Trihalomethanes', 'Turbidity']
target = 'Potability'

X = dataset[fitur]
y = dataset[target]

#5

#Korelasi Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(dataset.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Korelasi Heatmap")
plt.show()

#Distribusi Histogram Plot
plt.figure(figsize=(15, 12))
for i, col in enumerate(X):
    plt.subplot(3, 3, i + 1)
    sns.histplot(dataset[col], kde=True, color='skyblue')
    plt.title(f"Distribusi {col}")
plt.tight_layout()
plt.suptitle("Distribusi Histogram Atribut", y=1.02)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Normalisasi data ---
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Inisialisasi model
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier()
}

# Menyimpan hasil akurasi dan confusion matrix
results = {}

# Melatih dan mengevaluasi setiap model
for model_name, model in models.items():
    # Melatih model dengan data sebelum normalisasi
    model.fit(X_train, y_train)
    y_pred_before = model.predict(X_test)
    accuracy_before = accuracy_score(y_test, y_pred_before)
    cm_before = confusion_matrix(y_test, y_pred_before)

    # Melatih model dengan data setelah normalisasi
    model.fit(X_train_scaled, y_train)
    y_pred_after = model.predict(X_test_scaled)
    accuracy_after = accuracy_score(y_test, y_pred_after)
    cm_after = confusion_matrix(y_test, y_pred_after)

    # Menyimpan hasil evaluasi
    results[model_name] = {
        'accuracy_before': accuracy_before,
        'accuracy_after': accuracy_after,
        'cm_before': cm_before,
        'cm_after': cm_after
    }

# Menampilkan hasil akurasi dan confusion matrix
for model_name, result in results.items():
    print(f"\n{model_name}")
    print(f"  Akurasi Sebelum Normalisasi: {result['accuracy_before']:.4f}")
    print(f"  Akurasi Setelah Normalisasi: {result['accuracy_after']:.4f}")

    # Menampilkan confusion matrix sebelum dan setelah normalisasi
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Confusion Matrix Sebelum Normalisasi
    sns.heatmap(result['cm_before'], annot=True, fmt='d', cmap='Blues', xticklabels=['Tidak Layak', 'Layak'], yticklabels=['Tidak Layak', 'Layak'], ax=axes[0])
    axes[0].set_title(f'Confusion Matrix - {model_name} (Sebelum Normalisasi)')
    axes[0].set_xlabel('Prediksi')
    axes[0].set_ylabel('Aktual')

    # Confusion Matrix Setelah Normalisasi
    sns.heatmap(result['cm_after'], annot=True, fmt='d', cmap='Blues', xticklabels=['Tidak Layak', 'Layak'], yticklabels=['Tidak Layak', 'Layak'], ax=axes[1])
    axes[1].set_title(f'Confusion Matrix - {model_name} (Setelah Normalisasi)')
    axes[1].set_xlabel('Prediksi')
    axes[1].set_ylabel('Aktual')

    plt.tight_layout()
    plt.show()
